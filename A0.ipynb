{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "colab": {
      "name": "A0",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "tags": [
          "instructions"
        ],
        "id": "xZ7H7FmcDw5B"
      },
      "source": [
        "## CS431/631 Data Intensive Distributed Analytics\n",
        "### Winter 2022 - Assignment 0\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "tags": [
          "instructions"
        ],
        "id": "F4K1ZTGrDw5E"
      },
      "source": [
        "**Please edit this (text) cell to provide your name and UW student ID number!**\n",
        "* **Name:** k79wu\n",
        "* **ID:** 20775633"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBJ1H1i_ENGE"
      },
      "source": [
        "For this assignment, you will be using Python to do some analysis of the text of Shakespeare's plays.   Run the next block to download the text file (`Shakespeare.txt`) and the Python tokenizer module (`simple_tokenize.py`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcXDTtuqENqF"
      },
      "source": [
        "!wget -q https://student.cs.uwaterloo.ca/~cs451/content/cs431/Shakespeare.txt\n",
        "!wget -q https://student.cs.uwaterloo.ca/~cs451/content/cs431/simple_tokenize.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "tags": [
          "instructions"
        ],
        "id": "yDOanRXeDw5F"
      },
      "source": [
        "---\n",
        "\n",
        "\n",
        "Let's first try running some simple Python code to make sure that everything is set up properly and ready to go.   The code in the next box will open `Shakespeare.txt`, read the file line by line, and tokenize each line that it reads in.    Try running the code by selecting the box and typing `Shift-Return`, i.e., hit the carriage return key while you are holding the shift key.   It may take a few seconds to run."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "deletable": false,
        "tags": [
          "instructions"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQUhrqdADw5G",
        "outputId": "7079b451-3da4-4642-93ab-d2c6695b3a6f"
      },
      "source": [
        "# this imports the SimpleTokenize function from the simple_tokenize.py file that you uploaded\n",
        "from simple_tokenize import simple_tokenize\n",
        "\n",
        "# Now, let's tokenize Shakespeare's plays\n",
        "filename = 'Shakespeare.txt'\n",
        "with open(filename) as f:\n",
        "    for line in f:\n",
        "        # tokenize, one line at a time\n",
        "        t = simple_tokenize(line)\n",
        "t"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the', 'end']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "tags": [
          "instructions"
        ],
        "id": "5Hf7FVbiDw5H"
      },
      "source": [
        "---\n",
        "### Important\n",
        "\n",
        "The questions that follow ask you to implement functions whose prototypes are given to you. **Do _not_ change the prototypes of the functions. Do _not_ write code outside of the functions.** In particular, do not use the same cell as the function declaration invoke the function.\n",
        "\n",
        "You may use specific cells, identified by `# Your tests here`, for test purposes. Code in these cells will *not* be executed when marking your assignment.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "tags": [
          "instructions"
        ],
        "id": "23vjzVHSDw5I"
      },
      "source": [
        "#### Question 1  (2/10 marks):\n",
        "After the code has finished running, the notebook will display the resulting output immediately after cell.   In this case, you should see the output `['the', 'end']`. In the next cell, briefly explain why the code produced this output.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "tags": [
          "answer"
        ],
        "id": "eASRhGexDw5I"
      },
      "source": [
        "#### Your answer to Question 1:\n",
        "The program reads lines one by one, tokenizes them and save tokenized list to t. When reading the last line, we see that 'THE' and 'END' does not have apostrophe behind them, so they are transformed into lower case and put into a list, which is ['the', 'end']\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "tags": [
          "instructions"
        ],
        "id": "XyqvKBp6Dw5J"
      },
      "source": [
        "Now it is time for you to write some code.   Let's find the most frequently appearing tokens in Shakespeare's work.\n",
        "\n",
        "#### Question 2 (4/10 marks):\n",
        "In the next box, implement the function `top_50_tokens` using Python code that return the list of the 50 most frequently appearing tokens and their frequency, i.e., the number of times that each occurs.   Please use the `simple_tokenize` function, without modification, to tokenize the text, so that everyone is working with the same definition of what a token is.   If you wish, feel free to start with the Python code in the box above - just copy it from there and paste it below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "tags": [
          "code"
        ],
        "id": "CTdU0CO3Dw5K"
      },
      "source": [
        "from simple_tokenize import simple_tokenize\n",
        "\n",
        "# This program takes one file and return a list of list of the 50 most frequently appearing tokens and their frequency\n",
        "# top_50_tokens: Str -> (listof (listof Str Int))\n",
        "def top_50_tokens(filename='Shakespeare.txt'):\n",
        "    #initialize an empty list\n",
        "    top_50_tokens_list = []\n",
        "    \n",
        "    #initialize an empty dictionary\n",
        "    freq={}\n",
        "\n",
        "    # open the file\n",
        "    with open(filename) as f:\n",
        "      for line in f:\n",
        "          # tokenize, one line at a time\n",
        "          t = simple_tokenize(line)\n",
        "\n",
        "          # check words in tokenized list, if the word is in dictionary, update the\n",
        "          # frequency by adding one, else, add the word into the dictionary\n",
        "          for word in t:\n",
        "            if word in freq.keys():\n",
        "              freq[word]+=1\n",
        "            else:\n",
        "              freq[word]=1\n",
        "\n",
        "    # get top 50 appearing tokens by sorting dictionary by values and take first 50 tokens\n",
        "    sorted_keys=sorted(freq,key=lambda k: freq[k], reverse=True)[:50]\n",
        "    \n",
        "    # update top_50_tokens_list by getting values of those tokens\n",
        "    top_50_tokens_list=[[key, freq[key]] for key in sorted_keys]\n",
        "    \n",
        "    return top_50_tokens_list\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "tags": [
          "tests"
        ],
        "id": "G0tWVMiTDw5K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9a4e4be-fc22-4e84-dcf8-7c7d70f8dc1a"
      },
      "source": [
        "# Your tests here\n",
        "top_50_tokens(filename='Shakespeare.txt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['the', 27378],\n",
              " ['and', 26082],\n",
              " ['i', 20717],\n",
              " ['to', 19661],\n",
              " ['of', 17473],\n",
              " ['a', 14723],\n",
              " ['you', 13630],\n",
              " ['my', 12490],\n",
              " ['in', 10996],\n",
              " ['that', 10915],\n",
              " ['is', 9137],\n",
              " ['not', 8512],\n",
              " ['with', 7778],\n",
              " ['me', 7777],\n",
              " ['it', 7692],\n",
              " ['for', 7578],\n",
              " ['be', 6867],\n",
              " ['his', 6859],\n",
              " ['your', 6657],\n",
              " ['this', 6606],\n",
              " ['but', 6277],\n",
              " ['he', 6260],\n",
              " ['have', 5885],\n",
              " ['as', 5744],\n",
              " ['thou', 5491],\n",
              " ['him', 5205],\n",
              " ['so', 5056],\n",
              " ['will', 4977],\n",
              " ['what', 4469],\n",
              " ['thy', 4034],\n",
              " ['all', 3923],\n",
              " ['her', 3850],\n",
              " ['no', 3797],\n",
              " ['by', 3768],\n",
              " ['do', 3753],\n",
              " ['shall', 3592],\n",
              " ['if', 3500],\n",
              " ['are', 3405],\n",
              " ['we', 3298],\n",
              " ['thee', 3180],\n",
              " ['on', 3062],\n",
              " ['lord', 3062],\n",
              " ['our', 3061],\n",
              " ['king', 2871],\n",
              " ['good', 2834],\n",
              " ['now', 2789],\n",
              " ['sir', 2763],\n",
              " ['from', 2640],\n",
              " ['o', 2621],\n",
              " ['come', 2519]]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "tags": [
          "instructions"
        ],
        "id": "jFFC9DWxDw5L"
      },
      "source": [
        "Be sure to test the code that you have written by running it.   When you submit your notebook to us, we will run your code when we mark you assignment.   As a sanity test on you output, our reference implementation finds that the most frequent word is \"the\", which occurs 27378 times.\n",
        "\n",
        "---\n",
        "\n",
        "Once you have found the 50 most frequent tokens, let's move on to something slightly more complicated.\n",
        "\n",
        "#### Question 3 (4/10 marks):\n",
        "\n",
        "Instead of the most frequent tokens appearing in Shakespeare's works, suppose that we want a list of words that appear after the word \"perfect\", on the same line, in Shakespeare's text. \n",
        "(Note: the \"words\" we are interested in for this question are tokens, as returned by simple_tokenize.)\n",
        "\n",
        "For example, *All's Well That Ends Well* includes the line\n",
        ">  Ere I can perfect mine intents, to kneel.\n",
        "\n",
        "so \"mine\" should be part of the output, since it follows \"perfect\" on this line.  To keep the output from getting too long, include only words that appear after \"perfect\" on more than one line.\n",
        "\n",
        "In the next box, implement the function `perfect_x` that returns a dictionary of key/value pairs, where the keys are the words that follow perfect on more than one line, and the values the number of lines in which the pattern is observed. For instance, if 'x' follows 'perfect' on 3 different lines, the entry in the dictionary will be ('x':3) As a sanity check on your output, our reference implementation finds 5 such words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "tags": [
          "code"
        ],
        "id": "xe-JSeFYDw5M"
      },
      "source": [
        "from simple_tokenize import simple_tokenize\n",
        "\n",
        "# The program perfect_x takes a file and return a dictionary of words that follow 'perfect' on more than \n",
        "# one line along with its line freqeuncy\n",
        "# perfect_x: Str -> Dict(Str, Int)\n",
        "def perfect_x(filename = 'Shakespeare.txt'):\n",
        "    #initialize an empty dictionary\n",
        "    perfect_x_dict = {}\n",
        "\n",
        "    # open the file\n",
        "    with open(filename) as f:\n",
        "      for line in f:\n",
        "          # tokenize, one line at a time\n",
        "          t = simple_tokenize(line)\n",
        "\n",
        "          # get a list of indexes of 'perfect' in one line\n",
        "          perfect_indexes = [i for i, token in enumerate(t) if token=='perfect']\n",
        "\n",
        "          # get a list of all tokens immediately after 'perfect'\n",
        "          follower_list = [t[i+1] for i in perfect_indexes if i!=len(t)-1]\n",
        "\n",
        "          # remove all duplicate tokens in the list\n",
        "          follower_list = list(set(follower_list))\n",
        "\n",
        "          # add value by one if token existing in dict, otherwise add token into the dict\n",
        "          for follower in follower_list:\n",
        "            if follower in perfect_x_dict.keys():\n",
        "                  perfect_x_dict[follower]+=1\n",
        "            else:\n",
        "                  perfect_x_dict[follower]=1\n",
        "    \n",
        "    # filter the dictionary by checking if the value is greater than 1\n",
        "    perfect_x_dict={k:v for k,v in perfect_x_dict.items() if v>1}\n",
        "    \n",
        "    return perfect_x_dict\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "tags": [
          "tests"
        ],
        "id": "NoSRbXiMDw5M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea8143b4-a2a8-4863-c78c-e4e9b8f27aff"
      },
      "source": [
        "# Your tests here\n",
        "perfect_x('Shakespeare.txt')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'honour': 2, 'in': 4, 'love': 4, 'that': 2, 'yellow': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "tags": [
          "instructions"
        ],
        "id": "Q17qkDyRDw5M"
      },
      "source": [
        " When you are finished and ready to submit your assignment, download your .ipynb notebook file from Colab (File>Download .ipynb) to your machine, and then follow the submission instructions in the assignment."
      ]
    }
  ]
}